## What is the statim-ai project?

Nowdays it is easy to run AI models locally or on the cloud (at least for inference). But the experience is not always the best since the models by themselfs don't provide features that make them easy to use.

`statim-ai` wants to provide a great out-of-box experience running AI models locally or in the cloud by providing features that will help running those models in a production environment, without being tied to specific providers.

## What does it provides?

This projcect aims to provide Docker images ready to be used with LLM model(s), by adding a couple of usefull features:

- Job oriented, asynchronous, HTTP REST API
- SQLite database to store metadata about each request
- Support for multiple LLM models on the same instance
- After the image creation no more downloads are needed
- Easy to add new LLM models
- Logging

## How to start using?

Some context first:

The [statim-ai-server](https://github.com/statim-ai/statim-ai-server) repo provides the base image, without any model loaded, this is the scaffolding which other images will be built upon. The image generated by this repo contains the REST API, database support and all the other features. You don't need to touch this repo unless you want to contribute with new features or bug fixes.

Now that we know what the base image is, we can start looking at examples on how to add a model to the base image.

To add a model to the base image you can start by looking at the following repos, which have examples on how to do it for text based and image based models:
- [statim-ai-server-example-text-model](https://github.com/statim-ai/statim-ai-server-example-text-model)
- [statim-ai-server-example-image-model](https://github.com/statim-ai/statim-ai-server-example-image-model)

You can clone these repos and change as you wish to built your own server with the models that you need.
